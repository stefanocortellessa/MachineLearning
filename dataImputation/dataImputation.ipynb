{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autosave 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random as rand\n",
    "from numpy import array\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import zero_one_loss, log_loss\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openDataset(filename):\n",
    "    dataFile = open(filename, 'r')\n",
    "    dataFrame = pd.read_csv(dataFile, sep=',', header=0, dtype='str')\n",
    "    dataFile.close()\n",
    "\n",
    "    return dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#breast = openDataset('breast-cancer.csv')\n",
    "#breast = openDataset('hayes-roth.csv')\n",
    "breast = openDataset('tic-tac-toe.csv')\n",
    "\n",
    "breastCopy = breast.copy()\n",
    "originalDF = breastCopy.append(breast) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decide how much '?' randomly put in the currently row & put it in a random column position; do it for every sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upBound = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def randomicAssignment ():\n",
    "    k=0\n",
    "    for i in range(0, len(breast)):\n",
    "        maxMissingValues = rand.randint (0, upBound)\n",
    "        for j in range(0, maxMissingValues):\n",
    "            k += maxMissingValues\n",
    "            missingValues = rand.randint (0, len(breast.columns) - 1)\n",
    "            breast.iloc[i, missingValues] = '?'\n",
    "    \n",
    "    return breast, k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "breast, numberOfQuestionMarks = randomicAssignment()\n",
    "breast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breast = breastCopy.append(breast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One-Hot encoding on the dataset with '?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encodedDF = pd.get_dummies(breast)\n",
    "encodedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide input & output in with the latter is equal to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(dataframe, dataframeLabels):\n",
    "    y = dataframe[dataframeLabels].values\n",
    "    x = dataframe.drop(dataframeLabels, axis=1).values\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method that splits Training and Test Set not insterting ? in the TrainingSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainAndTest(x, y, yOriginal, index, medium):\n",
    "    xTrain = list(x[:medium])\n",
    "    xTest = []\n",
    "    yTrain = list(y[:medium])\n",
    "    yTest = []\n",
    "    yTestOriginal = []\n",
    "    count = 0\n",
    "    \n",
    "    \n",
    "    for i in range (medium, len(y)):\n",
    "        flag = False\n",
    "        for j in index:\n",
    "            if int(y[i][j]) == 1:\n",
    "                flag = True\n",
    "            else:   \n",
    "                flag = False \n",
    "                break  \n",
    "        if flag:\n",
    "            yTest.append(y[i].tolist())\n",
    "            yTestOriginal.append(yOriginal[i].tolist())\n",
    "            xTest.append(x[i].tolist())\n",
    "            count += 1\n",
    "    \n",
    "    return array(xTrain), array(xTest), array(yTrain), array(yTest), array(yTestOriginal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#method that splits insterting ? in the TrainingSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def splitTrainAndTest(x, y, yOriginal, index, medium):\n",
    "    \n",
    "    xTrain = [] \n",
    "    xTest = []\n",
    "    yTrain =[] \n",
    "    yTest = []\n",
    "    yTestOriginal = []\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(0, len(y)):\n",
    "        flag = False\n",
    "        for j in index:\n",
    "            if int(y[i][j]) == 1:\n",
    "                flag = True\n",
    "            else:   \n",
    "                flag = False \n",
    "                break  \n",
    "        if flag:\n",
    "            yTest.append(y[i].tolist())\n",
    "            yTestOriginal.append(yOriginal[i].tolist())\n",
    "            xTest.append(x[i].tolist())\n",
    "            count += 1\n",
    "        else:\n",
    "            yTrain.append(y[i].tolist())\n",
    "            xTrain.append(x[i].tolist()) \n",
    "    \n",
    "    return array(xTrain), array(xTest), array(yTrain), array(yTest), array(yTestOriginal)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeuralNets(xTrain, yTrain, hidden, iterations):\n",
    "    classifier = MLPClassifier(hidden_layer_sizes = hidden, max_iter = iterations)\n",
    "    classifier.fit(xTrain, yTrain) \n",
    "    \n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create every possible subset, for creating a Neural Network for every of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possibleSubsets(df, maximum):\n",
    "    subsetss = []\n",
    "    \n",
    "    for i in range (1, maximum +1):\n",
    "        for subset in itertools.combinations(df.columns, i):\n",
    "            subsetss.append(list(subset))\n",
    "    \n",
    "    return subsetss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labels is equal to a set of output columns of oneHotEncoding are under consideration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLabels(subset, oneHotLabels):\n",
    "    labels = []\n",
    "    \n",
    "    for label in subset:\n",
    "        for labelOneHot in oneHotLabels:\n",
    "            if label in labelOneHot:\n",
    "                labels.append(labelOneHot)\n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unknown is equal to the list of columns with '?' in oneHotEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createUnknownLabels(labels, unknown):\n",
    "    for label in labels:\n",
    "        if '?' in label:\n",
    "            unknown.append(label)\n",
    "    \n",
    "    return unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and predict probabilistic vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndPredictProba(classifier, xTest):\n",
    "    yPredProb = classifier.predict_proba(xTest)\n",
    "    \n",
    "    \n",
    "    return yPredProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Common training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAndPredict(classifier, xTest):\n",
    "    yPred = classifier.predict(xTest)    \n",
    "\n",
    "    return yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctlyReindex(index, yPred):\n",
    "    yPred = np.delete(yPred, index, axis=1)\n",
    "            \n",
    "    return yPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printZeroOneLoss(yTestOriginal, yPred):\n",
    "    Loss = zero_one_loss(yTestOriginal, yPred)\n",
    "    \n",
    "    print(\"Zero/One Loss:\")\n",
    "    print(Loss)\n",
    "    print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLogLoss(yTestOriginal, yPred):\n",
    "    Loss = log_loss(yTestOriginal, yPred)\n",
    "    \n",
    "    print(\"Log Loss:\")\n",
    "    print(Loss)\n",
    "    print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printPredicted(subset):\n",
    "    \n",
    "    print(\"Predicting: {subset}\".format(subset=subset))\n",
    "    print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTrainTest(xTrain, xTest):\n",
    "    \n",
    "    print(\"Train and Test splitting sizes:\")    \n",
    "    print(\"{train}% train\".format(train=int(round(100*len(xTrain)/(len(xTrain)+len(xTest))))))\n",
    "    print(\"{test}% test\".format(test=int(round(100*len(xTest)/(len(xTrain)+len(xTest))))))\n",
    "    print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printLabels(labels):\n",
    "    \n",
    "    print(\"Possible values to predict:\")\n",
    "    print(labels)\n",
    "    print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printProbabilityVector(yPredProb):\n",
    "\n",
    "    print('Probability Vector:')\n",
    "    print(yPredProb)\n",
    "    print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printQuestionMarks(newBreast):\n",
    "    \n",
    "    questionMarks = (numberOfQuestionMarks / (len(newBreast) * len(newBreast.columns)))\n",
    "            \n",
    "    print('Question marks percentage:')\n",
    "    print(round(questionMarks * 100), '%')\n",
    "    print( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printEverything(subset, xTrain, xTest, labels, yPredProb, yTestOriginal, yPred, newBreast):\n",
    "    \n",
    "    printPredicted(subset)\n",
    "    printTrainTest(xTrain, xTest)\n",
    "    printZeroOneLoss(yTestOriginal, yPred)\n",
    "    printLogLoss(yTestOriginal, yPred)\n",
    "    printLabels(labels)\n",
    "    printProbabilityVector(yPredProb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unknown = lista di colonne con il '?' di oneHotEncoding\n",
    "#index = indici colonne di unknown\n",
    "#labels = insieme delle colonne di output che stiamo considerando di oneHotEncoding\n",
    "#oneHotLabels = colonne del df codificato ('encodedDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probPredict(): \n",
    "    #medium's df index\n",
    "    medium = int((len(originalDF)+1)/2)\n",
    "    \n",
    "    #For every subset of possible columns as output\n",
    "    for subset in possibleSubsets(breast, upBound):\n",
    "        labels = [] \n",
    "        unknown = [] \n",
    "        oneHotLabels = encodedDF.columns \n",
    "        \n",
    "        labels = createLabels(subset, oneHotLabels)\n",
    "        \n",
    "        #Divide input and output where outputs are equal to output columns in encodedDF\n",
    "        x, y = preprocessing(encodedDF, labels)\n",
    "        \n",
    "        labels_original = [x for x in labels if \"?\" not in x ]        \n",
    "        \n",
    "        datasetOriginalOneHot = pd.get_dummies(originalDF) \n",
    "        #Equal, but for the original dataset\n",
    "        xOriginal, yOriginal = preprocessing(datasetOriginalOneHot, labels_original)\n",
    "            \n",
    "        #Create unknown list\n",
    "        unknown = createUnknownLabels(labels, unknown)\n",
    "        \n",
    "        #create index\n",
    "        index = [labels.index(x) for x in unknown] # indici colonne con ? con one_hot_encoding\n",
    "        \n",
    "        #Split train and test where test is equal yo rows containing '?' in output rows\n",
    "        xTrain, xTest, yTrain, yTest, yTestOriginal = splitTrainAndTest(x, y, yOriginal, index, medium)     \n",
    "        \n",
    "        if len(yTest) == 0: \n",
    "            print(\"no test entry: Finished! \\n\\n\\n\") \n",
    "            return   \n",
    "    \n",
    "        #Train e predict using Neural Nets\n",
    "        neurons = 100\n",
    "        classifier = NeuralNets(xTrain, yTrain, (neurons, neurons), 5000)\n",
    "        \n",
    "        yPredProb = trainAndPredictProba(classifier, xTest)\n",
    "        yPred = trainAndPredict(classifier, xTest)\n",
    "        \n",
    "        #Perform the reindex since deleting the considered column it changes\n",
    "        yPred = np.delete(yPred, index, axis=1)\n",
    "        \n",
    "        printEverything(subset, xTrain, xTest, labels, yPredProb, yTestOriginal, yPred, breast)\n",
    "\n",
    "        print( )\n",
    "        print( )\n",
    "        print( )\n",
    "    \n",
    "    return yPredProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probPredict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question mark percentage in the whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printQuestionMarks(breast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "i = 0\n",
    "\n",
    "def writer(possibleValues, probabilisticVector):\n",
    "    \n",
    "    global i \n",
    "    i += 1\n",
    "    \n",
    "    filename='data' + str(i) + '.csv'\n",
    "    \n",
    "    with open(filename, \"w\") as outfile:\n",
    "        for entries in possibleValues:\n",
    "            outfile.write(entries)\n",
    "            outfile.write(\";\")\n",
    "        \n",
    "        outfile.write(\"\\n\")\n",
    "        k = 0\n",
    "        for l in range(0, len(probabilisticVector)):\n",
    "            for values in probabilisticVector[l]:\n",
    "                for k in range(len(probabilisticVector[l])):\n",
    "                    if(k == len(probabilisticVector[0])):\n",
    "                        outfile.write(\"\\n\")\n",
    "                    else:\n",
    "                        outfile.write(str(values[k]))\n",
    "                        outfile.write(\";\")\n",
    "                        \n",
    "            \n",
    "    \n",
    "    return i"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
