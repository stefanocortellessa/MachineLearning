{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(500000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 500 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, time\n",
    "import random, csv\n",
    "from scipy.io import wavfile\n",
    "from scipy.fftpack import fft\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Registrazione voce, estensione '.wav' e salvataggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record(seconds = 2):\n",
    "    \n",
    "    CHUNK = 1024\n",
    "    FORMAT = pyaudio.paInt16\n",
    "    CHANNELS = 2\n",
    "    RATE = 44100\n",
    "    SECONDS = 2\n",
    "    \n",
    "    \n",
    "    frames = []\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    stream = audio.open(format = FORMAT,\n",
    "                        channels = CHANNELS,\n",
    "                        rate = RATE,\n",
    "                        input = True,\n",
    "                        frames_per_buffer = CHUNK)\n",
    "\n",
    "    print(\"Recording...\")\n",
    "\n",
    "    for i in range(0, int(RATE / CHUNK * SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    \n",
    "    audio.terminate()\n",
    "    \n",
    "    waveFile = wave.open(\"recordedVoice.wav\", 'wb')\n",
    "    waveFile.setnchannels(CHANNELS)\n",
    "    waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "    waveFile.setframerate(RATE)\n",
    "    waveFile.writeframes(b''.join(frames))\n",
    "    waveFile.close()\n",
    "    \n",
    "    print(\"Registration made!\")\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esecuzione trasformata di Fourier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourierConversion(filename, name, file):\n",
    "    \n",
    "    writ = str(name) + \",\"\n",
    "    fileOutput = open(str(file), \"a\")\n",
    "    fs, data = wavfile.read(filename)\n",
    "    \n",
    "    datas = data.T[0]\n",
    "    param = [(k / 2 ** 8.) * 2 - 1 for k in datas]\n",
    "    trasformation = fft(param)\n",
    "    \n",
    "    for i in range(0, len(trasformation)):\n",
    "        number = str(trasformation[i])\n",
    "        number = number.replace(\"(\", \"\")\n",
    "        number = number.replace(\")\", \"\")\n",
    "        number = complex(number).real\n",
    "        \n",
    "        if i == len(trasformation) - 1:\n",
    "            writ += str(number)\n",
    "        else:\n",
    "            writ += str(number) + \",\"\n",
    "            \n",
    "    fileOutput.write(writ + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea Training e Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createQueryAndTrainingSet():\n",
    "    dataSet = pd.read_csv(\"dataset.csv\", header=None)\n",
    "    lengthDataSet = len(dataSet)\n",
    "    indexes = np.arange(lengthDataSet).tolist()\n",
    "    indexesTrainingSet = random.sample(indexes, round(lengthDataSet * 90 / 100))\n",
    "    trainingSet = dataSet.ix[indexesTrainingSet]\n",
    "    testSet = dataSet.ix[list(set(indexes) - set(indexesTrainingSet))]\n",
    "\n",
    "    with open('trainingSet.csv', \"w+\") as file:\n",
    "        writer = csv.writer(file, delimiter=',')\n",
    "        writer.writerows(trainingSet.as_matrix())\n",
    "        \n",
    "    with open('testSet.csv', \"w+\") as file:\n",
    "        writer = csv.writer(file, delimiter=',')\n",
    "        writer.writerows(testSet.as_matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrittura/creazione Query Set\n",
    "# Trasformazione discreta Fourier di reali in sequenze complesse, attraverso la libreria fft (Fast Fourier Trasformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createQSet(fileName, file):\n",
    "    \n",
    "    writ = \"\"\n",
    "    fileOutput = open(str(file), \"w+\")\n",
    "    fs, data = wavfile.read(fileName)\n",
    "    \n",
    "    datas = data.T[0]\n",
    "    param = [(k / 2 ** 8.) * 2 - 1 for k in datas]\n",
    "    trasformation = fft(param)\n",
    "    \n",
    "    for i in range(0, len(trasformation)):\n",
    "        number = str(trasformation[i])\n",
    "        number = number.replace(\"(\", \"\")\n",
    "        number = number.replace(\")\", \"\")\n",
    "        number = complex(number).real\n",
    "        \n",
    "        if i == len(trasformation) - 1:\n",
    "            writ += str(number)\n",
    "        else:\n",
    "            writ += str(number) + \",\"\n",
    "        \n",
    "    fileOutput.write(writ + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indovina la parola pronunciata che è nel vocabolario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def said ():\n",
    "    record(seconds = 1)\n",
    "    \n",
    "    createQSet(\"recordedVoice.wav\", \"QueryDict.csv\")\n",
    "    query = pd.read_csv(\"QueryDict.csv\", header=None).as_matrix()\n",
    "    test = None\n",
    "\n",
    "    try:\n",
    "        test = newWordsNeuralNetwork.predict(query)\n",
    "    except NotFittedError as e:\n",
    "        dizionario = pd.read_csv(\"dictionary.csv\", header=None).as_matrix()\n",
    "        xTrain = dizionario[:, 1:]\n",
    "        yTrain = dizionario[:, 0]\n",
    "        newWordsNeuralNetwork.fit(xTrain, yTrain)\n",
    "            \n",
    "        joblib.dump(newWordsNeuralNetwork, 'newWordsNeuralNetwork.pkl')\n",
    "        test = newWordsNeuralNetwork.predict(query)\n",
    "\n",
    "    said = str(test[0])\n",
    "    print(\"You said \" + said + \"!\")\n",
    "    os.remove(\"QueryDict.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiunge una persona al dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add():\n",
    "    enteredName = input(\"Insert the person's name: \")\n",
    "    record()\n",
    "    fourierConversion(\"recordedVoice.wav\", enteredName, \"dataset.csv\")\n",
    "\n",
    "    print(\"Checking/Preparing trainingSet and testSet...\")\n",
    "    createQueryAndTrainingSet()\n",
    "    print(\"Done!\")\n",
    "    print(\"------------------\")\n",
    "        \n",
    "    trainSet = pd.read_csv(\"trainingSet.csv\", header=None).as_matrix()\n",
    "    xTrain = trainSet[:, 1:]\n",
    "    yTrain = trainSet[:, 0]\n",
    "        \n",
    "    print(\"I'm training, just a second...\")\n",
    "    neuralNetwork.fit(xTrain, yTrain)\n",
    "    joblib.dump(neuralNetwork, 'neuralNetwork.pkl') \n",
    "    print(\"Done!\")\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola l'accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    print(\"I'm predicting, just a second...\")\n",
    "    \n",
    "    testSet = pd.read_csv('testSet.csv', header=None)\n",
    "    queries = testSet.drop(0, axis=1)\n",
    "    prediction = neuralNetwork.predict(queries)\n",
    "    \n",
    "    print(\"Accuracy: \" + str(accuracy_score(testSet[0].as_matrix(), prediction) * 100) + \"%\" )\n",
    "    print(\"------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indovina chi ha parlato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess():\n",
    "    record()\n",
    "    print(\"I'm creating the QuerySet, just a second...\")\n",
    "    createQSet(\"recordedVoice.wav\",\"querySetTemp.csv\")\n",
    "    query = pd.read_csv(\"querySetTemp.csv\", header=None).as_matrix()\n",
    "    print(\"Done!\")\n",
    "    print(\"--------------\")\n",
    "    print(\"I'm thinking..\")\n",
    "    prediction = None\n",
    "\n",
    "    try:\n",
    "        prediction = neuralNetwork.predict(query)\n",
    "                \n",
    "    except NotFittedError as e:\n",
    "        trainSet = pd.read_csv(\"trainingSet.csv\", header=None).as_matrix()\n",
    "        xTrain = trainSet[:, 1:]\n",
    "        yTrain = trainSet[:, 0]\n",
    "        neuralNetwork.fit(xTrain, yTrain)\n",
    "                \n",
    "        joblib.dump(neuralNetwork, 'neural.pkl') \n",
    "        prediction = neuralNetwork.predict(query)\n",
    "    os.remove(\"querySetTemp.csv\") \n",
    "            \n",
    "    print(\"It's \" + str(prediction[-1]) + \"!\")\n",
    "    if input(\"Am I rigth? Write 'y' or 'n': \").strip() == \"y\":\n",
    "        print(\"---------------------------------\")\n",
    "        print(\"I'm updating the dataset, just a second...\")\n",
    "        fourierConversion(\"recordedVoice.wav\", prediction[-1], \"dataset.csv\")\n",
    "                \n",
    "        createQueryAndTrainingSet()\n",
    "                \n",
    "        trainSet = pd.read_csv(\"trainingSet.csv\", header=None).as_matrix()\n",
    "        xTrain = trainSet[:, 1:]\n",
    "        yTrain = trainSet[:, 0]\n",
    "        neuralNetwork.fit(xTrain, yTrain)\n",
    "                \n",
    "        joblib.dump(neuralNetwork, 'neuralNetwork.pkl')\n",
    "        print(\"The dataset is updated!\")  \n",
    "        print(\"------------------\")\n",
    "    else:\n",
    "        print(\"What a pity.. Let me try again!\")\n",
    "        print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiunge parola al vocabolario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocabulary():\n",
    "    word = input(\"Which word do you want to add? \")\n",
    "    record(seconds = 1)\n",
    "    fourierConversion(\"recordedVoice.wav\", word, \"dictionary.csv\")\n",
    "        \n",
    "    dictionary = pd.read_csv(\"dictionary.csv\", header=None).as_matrix()\n",
    "    xTrain = dictionary[:, 1:]\n",
    "    yTrain = dictionary[:, 0]\n",
    "        \n",
    "    print(\"I'm training, just a second..\")\n",
    "    newWordsNeuralNetwork.fit(xTrain, yTrain)\n",
    "    print(\"Done! wai while I'm creating a network dump\")\n",
    "    joblib.dump(newWordsNeuralNetwork, 'newWordsNeuralNetwork.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controlla se Training e Test Set sono presenti, altrimenti li crea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and Test sets are available!\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile('trainingSet.csv') or not os.path.isfile('testSet.csv') :\n",
    "    print(\"Training and Test sets are not available...\")\n",
    "    print(\"Wait a bit, I'm creating them!\")\n",
    "    createQueryAndTrainingSet()\n",
    "    print(\"Done!\")\n",
    "else:\n",
    "    print(\"Training and Test sets are available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralNetwork = None\n",
    "newWordsNeuralNetwork = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se non ancora mai creato, crea un dump della rete neurale già allenata sul training set,\n",
    "# altrimenti la carica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"neuralNetwork.pkl\"):\n",
    "    \n",
    "    neuralNetwork = MLPClassifier(hidden_layer_sizes=(2000))\n",
    "    trainSet = pd.read_csv(\"trainingSet.csv\", header=None).as_matrix()\n",
    "    xTrain = trainSet[:, 1:]\n",
    "    yTrain = trainSet[:, 0]\n",
    "    \n",
    "    print(\"The system is training itself, just a second...\")\n",
    "    neuralNetwork.fit(xTrain, yTrain)\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    joblib.dump(neuralNetwork, 'neuralNetwork.pkl') \n",
    "else:\n",
    "    \n",
    "    neuralNetwork = joblib.load('neuralNetwork.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(\"newWordsNeuralNetwork.pkl\"):\n",
    "    newWordsNeuralNetwork = MLPClassifier(hidden_layer_sizes=(1000), learning_rate='constant')\n",
    "else:\n",
    "    newWordsNeuralNetwork = joblib.load('newWordsNeuralNetwork.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you want to stop, write 'Stop'\n",
      "Digit 'Add' or 'Predict' or 'Guess' or 'Said' or 'Vocabulary': predict\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "I'm predicting, just a second...\n",
      "Accuracy: 60.0%\n",
      "------------------\n",
      "If you want to stop, write 'Stop'\n",
      "Digit 'Add' or 'Predict' or 'Guess' or 'Said' or 'Vocabulary': guess\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Recording...\n",
      "Registration made!\n",
      "------------------\n",
      "I'm creating the QuerySet, just a second...\n",
      "Done!\n",
      "--------------\n",
      "I'm thinking..\n",
      "It's Stefano!\n",
      "Am I rigth? Write 'y' or 'n': y\n",
      "---------------------------------\n",
      "I'm updating the dataset, just a second...\n",
      "The dataset is updated!\n",
      "------------------\n",
      "If you want to stop, write 'Stop'\n",
      "Digit 'Add' or 'Predict' or 'Guess' or 'Said' or 'Vocabulary': said\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "Recording...\n",
      "Registration made!\n",
      "------------------\n",
      "You said si!\n",
      "If you want to stop, write 'Stop'\n",
      "Digit 'Add' or 'Predict' or 'Guess' or 'Said' or 'Vocabulary': stop\n",
      "---------------------------------------------------------------------------------------------------------------\n",
      "------------------------\n",
      "Goodbye! See you soon :)\n"
     ]
    }
   ],
   "source": [
    "Start = \"BEGIN\"\n",
    "\n",
    "while str(Start) == \"BEGIN\":\n",
    "    print(\"If you want to stop, write 'Stop'\")\n",
    "    entered = input(\"Digit 'Add' or 'Predict' or 'Guess' or 'Said' or 'Vocabulary': \").strip().upper()\n",
    "    print(\"---------------------------------------------------------------------------------------------------------------\")\n",
    "    \n",
    "    if str(entered)== \"ADD\":  \n",
    "        add()\n",
    "        \n",
    "    elif str(entered) == \"GUESS\":\n",
    "        guess()\n",
    "                \n",
    "    elif str(entered)== \"VOCABULARY\":\n",
    "        vocabulary()\n",
    "        \n",
    "    elif str(entered)== \"SAID\":\n",
    "        said()\n",
    "        \n",
    "    elif str(entered) == \"PREDICT\":\n",
    "        predict()\n",
    "        \n",
    "    elif str(entered)== \"STOP\":\n",
    "        print(\"------------------------\")\n",
    "        print(\"Goodbye! See you soon :)\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
